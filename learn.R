# Import package for applying kmeans model
library(clue)

# Read in data generated by original Java, but only use first
# column (original signal)
xt = read.delim("trace.tsv", header=F)
xt1 = xt$V1
W = 32

# create window function
window = sin(pi*c(0:(W-1)/(W-1)))^2

# dot product with each window-length subsequence
r = t(sapply(c(1:200000), function(x) xt1[x:(x+W-1)]*window))

# normalize all the rows
r = t(apply(r, 1, function(x) x/sqrt(sum(x*x))))

# Apply kmeans to find 400 centroids -> shape dictionary
km = kmeans(r, 400, iter.max=20)
dict = km$centers

# Skip along by half of window length and normalize each window
index = (0: (length(xt1)*2/W - 2))*W/2 + 1
r2 = t(sapply(index, function(i) xt1[i:(i+W-1)]*window))
scale = apply(r2, 1, function(x) sqrt(sum(x*x)))
r2 = t(scale(t(r2), center=FALSE, scale=scale))

# Find the matching entry in dictionary and scale it back up
cluster = cl_predict(km, r2)
windows = scale(t(dict[cluster,]), center=FALSE, scale=1/scale)

# Add first half of each reconstructed window to last half of
# previous window
current = c(as.vector(windows[1:(W/2),]), rep(0, W/2))
previous = c(rep(0, W/2), as.vector(windows[(W/2 + 1):W,]))
reconstruct = current + previous

# Construct data frame of original signal, reconstructed signal,
# and cluster index.  From here you can run Dunning's original
# R code to generate visualizations

xtrace = data.frame(V1=xt1, V2=reconstruct, V3=rep(c(cluster,0), each=16))
